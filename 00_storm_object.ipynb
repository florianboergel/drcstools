{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp storm\n",
    "from nbdev import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "\n",
    "from xarray.core.variable import Variable\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(format='%(levelname)s: %(message)s', level=logging.INFO)\n",
    "\n",
    "try:\n",
    "    import dask\n",
    "except:\n",
    "    logger.warning(\"Dask is not installed in your python environment. Xarray Dataset parallel computing will not work.\")\n",
    "\n",
    "\n",
    "# plotting\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    #import cartopy.crs as ccrs\n",
    "except:\n",
    "    logger.warning(\"Matplotlib and/or Cartopy is not installed in your python environment. Xarray Dataset plotting functions will not work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stormtracks\n",
    "\n",
    "> calculate stormtracks from SLP fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'derivative' from 'drcstools.derivative' (/mnt/c/Users/flori/Documents/git_repositories/drcstools/drcstools/derivative.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-78d2f958f22e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mstorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \"\"\"The constructor for storm track class. Initialize a storm instance.\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mIf\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mtry\u001b[0m \u001b[0mto\u001b[0m \u001b[0mload\u001b[0m \u001b[0mit\u001b[0m \u001b[0mdirectly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-78d2f958f22e>\u001b[0m in \u001b[0;36mstorm\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Imported methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mdrcstools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderivative\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mderivative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mdrcstools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderivative\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mharmonicRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mdrcstools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mderivative\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalc_dX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'derivative' from 'drcstools.derivative' (/mnt/c/Users/flori/Documents/git_repositories/drcstools/drcstools/derivative.py)"
     ]
    }
   ],
   "source": [
    "#export\n",
    "class storm():\n",
    "    \"\"\"The constructor for storm track class. Initialize a storm instance.\n",
    "        \n",
    "        If filename is given, try to load it directly.\n",
    "        Arguments to the load function can be passed as key=value argument.\n",
    "        Parameters\n",
    "        ----------\n",
    "            filename : string\n",
    "                Datapath + filename.nc\n",
    "            ds : dataset\n",
    "                xarray dataset\n",
    "            anomaly: bool\n",
    "                calculates anomaly in time\n",
    "    \"\"\"\n",
    "    def __init__(self, filename=\"\", ds=None, anomaly = True, **kwargs):\n",
    "        \n",
    "        self._anomaly = anomaly\n",
    "        \n",
    "        if not filename:\n",
    "            if ds is None:\n",
    "                self.ds = None\n",
    "            else:\n",
    "                self.ds = ds\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            self.ds = None\n",
    "            self.read(filename, **kwargs)\n",
    "        except (OSError, IOError, RuntimeError):\n",
    "            try:\n",
    "                self.read(filename, **kwargs)\n",
    "            except Exception:\n",
    "                raise IOError(\"Unkown fileformat. Known formats are netcdf.\")\n",
    "\n",
    "    # Imported methods\n",
    "    \n",
    "    from drcstools.derivative import derivative \n",
    "    from drcstools.derivative import harmonicRegression\n",
    "    from drcstools.derivative import calc_dX\n",
    "      \n",
    "    def __repr__(self):\n",
    "        try:\n",
    "            string = \"\\\n",
    "            Xarray dataset with {} time steps. \\n\\\n",
    "            Available fields: {}\".format(\n",
    "                self.ntime, \", \".join(self.variables)\n",
    "            )\n",
    "        except AttributeError:\n",
    "            # Assume it's an empty Blocking()\n",
    "            string = \"\\\n",
    "            Empty contrack container.\\n\\\n",
    "            Hint: use read() to load data.\"\n",
    "        return string\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'Class {}: \\n{}'.format(self.__class__.__name__, self.ds)\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.ds)\n",
    "    \n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.__dict__:\n",
    "            return getattr(self, attr)\n",
    "        return getattr(self.ds, attr)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.ds[key]\n",
    "\n",
    "    @property\n",
    "    def ntime(self):\n",
    "        \"\"\"Return the number of time steps\"\"\"\n",
    "        if len(self.ds.dims) != 3:\n",
    "            logger.warning(\n",
    "                \"\\nBe careful with the dimensions, \"\n",
    "                \"you want dims = 3 and shape:\\n\"\n",
    "                \"(latitude, longitude, time)\"\n",
    "            )\n",
    "            return self.ds.dims[self._get_name_time()]\n",
    "        return self.ds.dims[self._get_name_time()]\n",
    "\n",
    "    @property\n",
    "    def variables(self):\n",
    "        \"\"\"Return the names of the variables\"\"\"\n",
    "        return list(self.ds.data_vars)\n",
    "    \n",
    "    @property\n",
    "    def dimensions(self):\n",
    "        \"\"\"Return the names of the dimensions\"\"\"\n",
    "        return list(self.ds.dims)\n",
    "    \n",
    "    @property\n",
    "    def grid(self):\n",
    "        \"\"\"Return the number of longitude and latitude grid\"\"\"\n",
    "        if len(self.ds.dims) != 3:\n",
    "            logger.warning(\n",
    "                \"\\nBe careful with the dimensions, \"\n",
    "                \"you want dims = 3 and shape:\\n\"\n",
    "                \"(latitude, longitude, time)\"\n",
    "            )\n",
    "            return None\n",
    "        string = \"\\\n",
    "        latitude: {} \\n\\\n",
    "        longitude: {}\".format(\n",
    "            self.ds.dims[self._get_name_latitude()], self.ds.dims[self._get_name_longitude()]\n",
    "        ) \n",
    "        print(string)\n",
    "\n",
    "    @property\n",
    "    def dataset(self):\n",
    "        \"\"\"Return the dataset\"\"\"\n",
    "        return self.ds\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Read / Import / Save data\n",
    "    \n",
    "    def read(self, filename, **kwargs):\n",
    "        \"\"\"\n",
    "        Reads a file into a xarray dataset.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "            filename : string\n",
    "                Valid path + filename\n",
    "        \"\"\"\n",
    "        if self.ds is None:\n",
    "            self.ds = xr.open_dataset(filename, **kwargs)\n",
    "            if self._anomaly == True:\n",
    "                self.ds = self.ds - self.ds.mean(self._get_name_time())\n",
    "            logger.debug('read: {}'.format(self.__str__))\n",
    "        else:\n",
    "            errmsg = 'contrack() is already set!'\n",
    "            raise ValueError(errmsg)\n",
    "            \n",
    "    def read_xarray(self, ds):\n",
    "        \"\"\"\n",
    "        Read an existing xarray data set.\n",
    "        \n",
    "        Parameter:\n",
    "        ----------\n",
    "            ds: data set\n",
    "                Valid xarray data set.\n",
    "        \"\"\"\n",
    "        if self.ds is None:\n",
    "            if not isinstance(ds, xr.core.dataset.Dataset):\n",
    "                errmsg = 'ds has to be a xarray data set!'\n",
    "                raise ValueError(errmsg)\n",
    "            self.ds = ds\n",
    "            logger.debug('read_xarray: {}'.format(self.__str__))\n",
    "        else:\n",
    "            errmsg = 'contrack() is already set!'\n",
    "            raise ValueError(errmsg)\n",
    " \n",
    "# Set up / Check dimensions\n",
    "   \n",
    "    def set_up(self,\n",
    "               time_name=None,\n",
    "               longitude_name=None,\n",
    "               latitude_name=None,\n",
    "               force=False,\n",
    "               write=True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Prepares the dataset for storm tracking. Does consistency checks\n",
    "        and tests if all required information is available. Sets (automatically \n",
    "        or manually) internal variables and dimensions.\n",
    "        Parameters\n",
    "        ----------\n",
    "            time_name : string, optional\n",
    "                Name of time dimension. The default is None.\n",
    "            longitude_name : string, optional\n",
    "                Name of longitude dimension. The default is None.\n",
    "            latitude_name : string, optional\n",
    "                Name of latitude dimension. The default is None.\n",
    "            force=False: bool, optional \n",
    "                Skip some consistency checks.\n",
    "            write=True: bool, optional\n",
    "                Print name of dimensions.\n",
    "        Returns\n",
    "        -------\n",
    "            None.\n",
    "        \"\"\"\n",
    "\n",
    "        # set dimensions\n",
    "        if time_name is None:\n",
    "            self._time_name = self._get_name_time()  \n",
    "        else:\n",
    "            self._time_name = time_name\n",
    "        if longitude_name is None:\n",
    "            self._longitude_name = self._get_name_longitude()\n",
    "        else:\n",
    "            self._longitude_name = longitude_name\n",
    "        if latitude_name is None:\n",
    "            self._latitude_name = self._get_name_latitude()\n",
    "        else:\n",
    "            self._latitude_name = latitude_name\n",
    "\n",
    "        # set resolution\n",
    "        if (self._longitude_name and self._latitude_name) is not None:\n",
    "            self._dlon =  self._get_resolution(self._longitude_name, force=force)\n",
    "            self._dlat =  self._get_resolution(self._latitude_name, force=force)\n",
    "\n",
    "        if self._time_name is not None:\n",
    "            self._dtime = self._get_resolution(self._time_name, force=force)\n",
    "       \n",
    "        # Transpose data\n",
    "        self.ds = self.ds.transpose(self._time_name,\n",
    "                                    self._latitude_name,\n",
    "                                    self._longitude_name) \n",
    "        # print names    \n",
    "        if write:\n",
    "            logger.info(\n",
    "                \"\\n time: '{}'\\n\"\n",
    "                \" longitude: '{}'\\n\"\n",
    "                \" latitude: '{}'\\n\".format(\n",
    "                self._time_name, \n",
    "                self._longitude_name,\n",
    "                self._latitude_name)\n",
    "            )\n",
    "\n",
    "    \n",
    "    def _get_name_time(self):\n",
    "        \"\"\"\n",
    "        check for 'time' dimension and return name\n",
    "        \"\"\"\n",
    "        # check unit\n",
    "        for dim in self.ds.dims:\n",
    "            if (('units' in self.ds[dim].attrs and\n",
    "                'since' in self.ds[dim].attrs['units']) or \n",
    "                ('units' in self.ds[dim].encoding and\n",
    "                 'since' in self.ds[dim].encoding['units']) or\n",
    "                dim in ['time']):\n",
    "                return dim\n",
    "        # check dtype\n",
    "        for dim in self.ds.variables:\n",
    "            try:\n",
    "                var = self.ds[dim].data[0]\n",
    "            except IndexError:\n",
    "                var = self.ds[dim].data\n",
    "            if isinstance(var, datetime64):\n",
    "                return dim   \n",
    "        # no 'time' dimension found\n",
    "        logger.warning(\n",
    "            \"\\n 'time' dimension (dtype='datetime64[ns]') not found.\"\n",
    "        )\n",
    "        return None     \n",
    "\n",
    "\n",
    "    def _get_name_longitude(self):\n",
    "        \"\"\"\n",
    "        check for 'longitude' dimension and return name\n",
    "        \"\"\"\n",
    "        for dim in self.ds.dims:\n",
    "            if (('units' in self.ds[dim].attrs and\n",
    "               self.ds[dim].attrs['units'] in ['degree_east', 'degrees_east']) or\n",
    "               dim in ['lon', 'longitude', 'x']):\n",
    "               return dim\n",
    "        # no 'longitude' dimension found\n",
    "        logger.warning(\n",
    "            \"\\n 'longitude' dimension (unit='degrees_east') not found.\"\n",
    "        )\n",
    "        return None\n",
    "\n",
    "\n",
    "    def _get_name_latitude(self):\n",
    "        \"\"\"\n",
    "        check for 'latitude' dimension and return name\n",
    "        \"\"\"\n",
    "        for dim in self.ds.dims:\n",
    "            if (('units' in self.ds[dim].attrs  and\n",
    "                self.ds[dim].attrs['units'] in ['degree_north', 'degrees_north']) or\n",
    "                dim in ['lat', 'latitude', 'y']):\n",
    "                return dim\n",
    "        # no 'latitude' dimension found\n",
    "        logger.warning(\n",
    "            \"\\n 'latitude' dimension (unit='degrees_north') not found.\"\n",
    "        )\n",
    "        return None\n",
    "            \n",
    "    def _get_resolution(self, dim, force=False):\n",
    "        \"\"\"\n",
    "        set spatial (lat/lon) and temporal (time) resolution\n",
    "        \"\"\"\n",
    "        # time dimension in hours\n",
    "        if dim == self._time_name:\n",
    "            try:\n",
    "                var = self.ds[dim].to_index()\n",
    "                delta = np.unique((\n",
    "                    self.ds[dim].to_index()[1:] - \n",
    "                    self.ds[dim].to_index()[:-1])\n",
    "                    .astype('timedelta64[h]')\n",
    "                )\n",
    "            except AttributeError:  # dates outside of normal range\n",
    "                # we can still move on if the unit is \"days since ...\"\n",
    "                if ('units' in self.ds[dim].attrs and\n",
    "                    'days' in self.ds[dim].attrs['units']):\n",
    "                    var = self.ds[dim].data\n",
    "                    delta = np.unique(var[1:] - var[:-1])\n",
    "                else:\n",
    "                    errmsg = 'Can not decode time with unit {}'.format(\n",
    "                        self.ds[dim].attrs['units'])\n",
    "                    raise ValueError(errmsg)\n",
    "        # lat/lon dimension in Degree\n",
    "        else:\n",
    "            delta = abs(np.unique((\n",
    "                self.ds[dim].data[1:] - \n",
    "                self.ds[dim].data[:-1])\n",
    "            ))\n",
    "        # check resolution\n",
    "        if len(delta) > 1:\n",
    "            errmsg = 'No regular grid found for dimension {}.\\n\\\n",
    "            Hint: use set_up(force=True).'.format(dim)\n",
    "            if force and dim != self._time_name:\n",
    "                logging.warning(errmsg)\n",
    "                logmsg = ' '.join(['force=True: using mean of non-equidistant',\n",
    "                                   'grid {}'.format(delta)])\n",
    "                logging.warning(logmsg)\n",
    "                delta = round(delta.mean(), 2)\n",
    "            else:\n",
    "                if dim == self._time_name:\n",
    "                    logging.warning(errmsg)\n",
    "                else:\n",
    "                    raise ValueError(errmsg)\n",
    "        elif delta[0] == 0:\n",
    "            errmsg = 'Two equivalent values found for dimension {}.'.format(\n",
    "                dim)\n",
    "            raise ValueError(errmsg)\n",
    "        elif delta[0] < 0:\n",
    "            errmsg = ' '.join(['{} not increasing. This should',\n",
    "                                   'not happen?!']).format(dim)\n",
    "            raise ValueError(errmsg)\n",
    "            \n",
    "        return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"storm.read\" class=\"doc_header\"><code>storm.read</code><a href=\"__main__.py#L119\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>storm.read</code>(**`filename`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Reads a file into a xarray dataset.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "    filename : string\n",
       "        Valid path + filename"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(storm.read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"storm.read_xarray\" class=\"doc_header\"><code>storm.read_xarray</code><a href=\"__main__.py#L137\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>storm.read_xarray</code>(**`ds`**)\n",
       "\n",
       "Read an existing xarray data set.\n",
       "\n",
       "Parameter:\n",
       "----------\n",
       "    ds: data set\n",
       "        Valid xarray data set."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(storm.read_xarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"storm.set_up\" class=\"doc_header\"><code>storm.set_up</code><a href=\"__main__.py#L158\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>storm.set_up</code>(**`time_name`**=*`None`*, **`longitude_name`**=*`None`*, **`latitude_name`**=*`None`*, **`force`**=*`False`*, **`write`**=*`True`*)\n",
       "\n",
       "Prepares the dataset for storm tracking. Does consistency checks\n",
       "and tests if all required information is available. Sets (automatically \n",
       "or manually) internal variables and dimensions.\n",
       "Parameters\n",
       "----------\n",
       "    time_name : string, optional\n",
       "        Name of time dimension. The default is None.\n",
       "    longitude_name : string, optional\n",
       "        Name of longitude dimension. The default is None.\n",
       "    latitude_name : string, optional\n",
       "        Name of latitude dimension. The default is None.\n",
       "    force=False: bool, optional \n",
       "        Skip some consistency checks.\n",
       "    write=True: bool, optional\n",
       "        Print name of dimensions.\n",
       "Returns\n",
       "-------\n",
       "    None."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(storm.set_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"storm._get_resolution\" class=\"doc_header\"><code>storm._get_resolution</code><a href=\"__main__.py#L282\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>storm._get_resolution</code>(**`dim`**, **`force`**=*`False`*)\n",
       "\n",
       "set spatial (lat/lon) and temporal (time) resolution"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(storm._get_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"storm._get_name_time\" class=\"doc_header\"><code>storm._get_name_time</code><a href=\"__main__.py#L224\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>storm._get_name_time</code>()\n",
       "\n",
       "check for 'time' dimension and return name"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(storm._get_name_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"storm._get_name_longitude\" class=\"doc_header\"><code>storm._get_name_longitude</code><a href=\"__main__.py#L251\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>storm._get_name_longitude</code>()\n",
       "\n",
       "check for 'longitude' dimension and return name"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(storm._get_name_longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"storm._get_name_longitude\" class=\"doc_header\"><code>storm._get_name_longitude</code><a href=\"__main__.py#L251\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>storm._get_name_longitude</code>()\n",
       "\n",
       "check for 'longitude' dimension and return name"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(storm._get_name_longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
